{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2590fd22-9096-4f87-8412-ad38ff375727",
   "metadata": {},
   "source": [
    "## Load Earth System Science Data (ESSD) datasets\n",
    "\n",
    "Copyright (C) 2021 OS-Climate\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n",
    "\n",
    "Contributed by Michael Tiemann (Github: MichaelTiemannOSC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6dc33c-ef3a-4820-a196-1b299d04a5da",
   "metadata": {},
   "source": [
    "Load Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9272c4-2f67-4769-b994-f4f110da425f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# From the AWS Account page, copy the export scripts from the appropriate role using the \"Command Line or Programmatic Access\" link\n",
    "# Paste the copied text into ~/credentials.env\n",
    "\n",
    "from dotenv import dotenv_values, load_dotenv\n",
    "import os\n",
    "import pathlib\n",
    "import sys\n",
    "\n",
    "dotenv_dir = os.environ.get('CREDENTIAL_DOTENV_DIR', os.environ.get('PWD', '/opt/app-root/src'))\n",
    "dotenv_path = pathlib.Path(dotenv_dir) / 'credentials.env'\n",
    "if os.path.exists(dotenv_path):\n",
    "    load_dotenv(dotenv_path=dotenv_path,override=True)\n",
    "\n",
    "# import sys\n",
    "# sys.path.append('../src/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab4a677-d6b3-4aa7-bffd-52d6c7e90273",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import openpyxl\n",
    "\n",
    "import pint\n",
    "import pint_pandas\n",
    "import iam_units\n",
    "from openscm_units import unit_registry\n",
    "pint_pandas.PintType.ureg = unit_registry\n",
    "ureg = unit_registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1604f52a-d5dc-424e-8275-8dba4753f7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import osc_ingest_trino as osc\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import json\n",
    "import io\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2554e5b-cac3-4495-b9f5-2b08da83c6b6",
   "metadata": {},
   "source": [
    "Create an S3 resource for the bucket holding source data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f457d9c-cd23-41c4-bdb9-051b401a8951",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "s3_source = boto3.resource(\n",
    "    service_name=\"s3\",\n",
    "    endpoint_url=os.environ['S3_LANDING_ENDPOINT'],\n",
    "    aws_access_key_id=os.environ['S3_LANDING_ACCESS_KEY'],\n",
    "    aws_secret_access_key=os.environ['S3_LANDING_SECRET_KEY'],\n",
    ")\n",
    "bucket = s3_source.Bucket(os.environ['S3_LANDING_BUCKET'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f7dcf7-352a-4df6-bdba-016a3713773c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an S3 client.  We will user later when we write out data and metadata\n",
    "s3_trino = boto3.client(\n",
    "    service_name=\"s3\",\n",
    "    endpoint_url=os.environ['S3_DEV_ENDPOINT'],\n",
    "    aws_access_key_id=os.environ['S3_DEV_ACCESS_KEY'],\n",
    "    aws_secret_access_key=os.environ['S3_DEV_SECRET_KEY'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf48b3d-4b39-406b-8bb6-8ad5998a25d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import trino\n",
    "from sqlalchemy.engine import create_engine\n",
    "\n",
    "env_var_prefix = 'TRINO'\n",
    "\n",
    "sqlstring = 'trino://{user}@{host}:{port}/'.format(\n",
    "    user = os.environ[f'{env_var_prefix}_USER'],\n",
    "    host = os.environ[f'{env_var_prefix}_HOST'],\n",
    "    port = os.environ[f'{env_var_prefix}_PORT']\n",
    ")\n",
    "sqlargs = {\n",
    "    'auth': trino.auth.JWTAuthentication(os.environ[f'{env_var_prefix}_PASSWD']),\n",
    "    'http_scheme': 'https',\n",
    "    'catalog': 'osc_datacommons_dev'\n",
    "}\n",
    "engine = create_engine(sqlstring, connect_args = sqlargs)\n",
    "connection = engine.connect()\n",
    "\n",
    "trino_bucket = osc.attach_s3_bucket(\"S3_DEV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a0dce7-1762-4605-8617-f2bf6d649f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "ingest_catalog = 'osc_datacommons_dev'\n",
    "ingest_schema = 'sandbox'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb96687d-74a7-46d8-9944-b63fddf11bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show available schemas to ensure trino connection is set correctly\n",
    "schema_read = engine.execute(f'show schemas in {ingest_catalog}')\n",
    "for row in schema_read.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4544e38-c59b-4a49-907f-83db1e0bc16b",
   "metadata": {},
   "source": [
    "Load ESSD data file using pandas *read_excel* and using *ingest_uuid* as the global UUID for this ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae08bca0-02c2-450d-82ca-9c4d7ecc78cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Much better to use disk than memory for large datasets (at least as far as notebook resources are concerned)!\n",
    "s3_essd_file = bObj = bucket.Object('ESSD/essd_ghg_data.xlsx')\n",
    "essd_tmpfile = f'/tmp/essd-data.xlsx'\n",
    "s3_essd_file.download_file(essd_tmpfile)\n",
    "timestamp = bObj.last_modified.isoformat()\n",
    "\n",
    "# It takes ~90 seconds (!) to load nearly 600K rows of data\n",
    "df = pd.read_excel(essd_tmpfile, sheet_name='data',\n",
    "                   converters={'year': lambda x: pd.to_datetime(x, format='%Y')},\n",
    "                   dtype={'gwp100_ar5':'int32', 'value':'float64'},\n",
    "                   engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75e0a3a-1baa-47c9-96c7-3ac826a1886d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put year at the end to make for more friendly partitioning\n",
    "year_index = df.columns.get_loc('year')\n",
    "essd_data_df = df[df.columns[:year_index].to_list()\n",
    "                  + df.columns[year_index+1:].to_list()\n",
    "                  + [df.columns[year_index]]]\n",
    "essd_data_df = essd_data_df.convert_dtypes()\n",
    "\n",
    "display(essd_data_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0befb864-3e0c-4357-8b24-5caeaea65de6",
   "metadata": {},
   "source": [
    "Construct the combined metadata by merging existing table metadata and custom metadata.\n",
    "Note: The metadata content must be JSON serialisable and encoded as bytes; the metadata key must also be encoded as bytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa06ed4-4092-46bd-925e-8701cd367249",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "essd_content_df = pd.read_excel(essd_tmpfile, sheet_name='info', header=None).dropna(axis=0).set_index(0).T\n",
    "custom_meta_content = {\n",
    "    'title': 'Earth System Science Data (ESSD) Dataset',\n",
    "    'author': essd_content_df[['Author & contact']].squeeze(),\n",
    "    'contact': essd_content_df[['Author & contact']].squeeze(),\n",
    "    'description': essd_content_df[['Data description']].squeeze(),\n",
    "    'release_date': essd_content_df[['Last date of compilation']].squeeze(),\n",
    "    # How should we describe our transformative step here?\n",
    "}\n",
    "\n",
    "essd_metadata_df = pd.read_excel(essd_tmpfile, sheet_name='metadata')\n",
    "custom_meta_fields = { d['Variable']: {k:v for k,v in d.items() if k!='Variable' and v==v} for d in essd_metadata_df.to_dict('records') }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c51fc5b-51a1-43a8-a0a0-880f6bf73fa6",
   "metadata": {},
   "source": [
    "The schemaname for this table is `essd`.  Dunno if it's a good idea or simply redundant to prefix the tablename with `essd_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5b88b7-7a70-4394-89f4-7bf019d28a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "essd_data_df.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eeeaaba-ab88-48a2-8f29-71a1a80d47e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ingest_table = 'ghg_data'\n",
    "columnschema = osc.create_table_schema_pairs(essd_data_df,\n",
    "                                             typemap={\"datetime64[ns]\":\"timestamp(6)\"})\n",
    "\n",
    "drop_table = engine.execute(f\"drop table if exists {ingest_schema}.{ingest_table}\")\n",
    "drop_table.fetchall()\n",
    "\n",
    "tabledef = f\"\"\"\n",
    "create table if not exists {ingest_catalog}.{ingest_schema}.{ingest_table}(\n",
    "{columnschema}\n",
    ") with (\n",
    "format = 'ORC',\n",
    "partitioning = array['year']\n",
    ")\n",
    "\"\"\"\n",
    "print(tabledef)\n",
    "qres = engine.execute(tabledef)\n",
    "print(qres.fetchall())\n",
    "essd_data_df.to_sql(ingest_table,\n",
    "                    con=engine, schema=ingest_schema, if_exists='append',\n",
    "                    index=False,\n",
    "                    method=osc.TrinoBatchInsert(batch_size = 4000, verbose = False))\n",
    "del(essd_data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a88136-839c-4187-bd75-8a1da7da343b",
   "metadata": {},
   "source": [
    "Verify that we can restore data and metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b90213-e3e3-4cc2-bd74-e4ed0d2946b4",
   "metadata": {},
   "source": [
    "Grab Sector, Region, 100yr GWPs, and GH4_gwps from one of the two main ESSD data tables (they are the same in both)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406b928c-5379-4db4-8364-2f53a550b6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "essd_sectors_df = pd.read_excel(essd_tmpfile, sheet_name='sector_classification', engine='openpyxl').convert_dtypes()\n",
    "\n",
    "display(essd_sectors_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341b9cfe-c646-4721-b287-48add08422f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_meta_content = {\n",
    "    'title': 'Earth System Science Data (ESSD) Sector Classification',\n",
    "    'author': essd_content_df[['Author & contact']].squeeze(),\n",
    "    'contact': essd_content_df[['Author & contact']].squeeze(),\n",
    "    'description': essd_content_df[['Sectors']].squeeze(),\n",
    "    'release_date': essd_content_df[['Last date of compilation']].squeeze(),\n",
    "    # How should we describe our transformative step here?\n",
    "}\n",
    "\n",
    "custom_meta_fields = None\n",
    "\n",
    "ingest_table = 'sectors'\n",
    "columnschema = osc.create_table_schema_pairs(essd_sectors_df,\n",
    "                                             typemap={\"datetime64[ns]\":\"timestamp(6)\"})\n",
    "\n",
    "drop_table = engine.execute(f\"drop table if exists {ingest_schema}.{ingest_table}\")\n",
    "drop_table.fetchall()\n",
    "\n",
    "tabledef = f\"\"\"\n",
    "create table if not exists {ingest_catalog}.{ingest_schema}.{ingest_table}(\n",
    "{columnschema}\n",
    ") with (\n",
    "format = 'ORC'\n",
    ")\n",
    "\"\"\"\n",
    "print(tabledef)\n",
    "qres = engine.execute(tabledef)\n",
    "print(qres.fetchall())\n",
    "essd_sectors_df.to_sql(ingest_table,\n",
    "                       con=engine, schema=ingest_schema, if_exists='append',\n",
    "                       index=False,\n",
    "                       method=osc.TrinoBatchInsert(batch_size = 4000, verbose = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816c3136-b860-496b-985e-65f8be8f9a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "essd_regions_df = pd.read_excel(essd_tmpfile, sheet_name='region_classification', engine='openpyxl').convert_dtypes()\n",
    "\n",
    "display(essd_regions_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281f95dc-bc29-4257-841d-120ad40aad2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_meta_content = {\n",
    "    'title': 'Earth System Science Data (ESSD) Region Classification',\n",
    "    'author': essd_content_df[['Author & contact']].squeeze(),\n",
    "    'contact': essd_content_df[['Author & contact']].squeeze(),\n",
    "    'description': essd_content_df[['Regions']].squeeze(),\n",
    "    'release_date': essd_content_df[['Last date of compilation']].squeeze(),\n",
    "    # How should we describe our transformative step here?\n",
    "}\n",
    "\n",
    "custom_meta_fields = None\n",
    "\n",
    "ingest_table = 'regions'\n",
    "columnschema = osc.create_table_schema_pairs(essd_regions_df,\n",
    "                                             typemap={\"datetime64[ns]\":\"timestamp(6)\"})\n",
    "\n",
    "drop_table = engine.execute(f\"drop table if exists {ingest_schema}.{ingest_table}\")\n",
    "drop_table.fetchall()\n",
    "\n",
    "tabledef = f\"\"\"\n",
    "create table if not exists {ingest_catalog}.{ingest_schema}.{ingest_table}(\n",
    "{columnschema}\n",
    ") with (\n",
    "format = 'ORC'\n",
    ")\n",
    "\"\"\"\n",
    "print(tabledef)\n",
    "qres = engine.execute(tabledef)\n",
    "print(qres.fetchall())\n",
    "essd_regions_df.to_sql(ingest_table,\n",
    "                       con=engine, schema=ingest_schema, if_exists='append',\n",
    "                       index=False,\n",
    "                       method=osc.TrinoBatchInsert(batch_size = 4000, verbose = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1821108-8a37-498b-b72b-7fc1bca07b97",
   "metadata": {},
   "source": [
    "Now deal with the gas species.  We'll annotate our dataframe with PINT units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dc2fa6-9ee1-4fd6-a4e3-1726181ef786",
   "metadata": {},
   "outputs": [],
   "source": [
    "essd_gwp_df = pd.read_excel(essd_tmpfile, sheet_name='100_yr_gwps', dtype={'gwp_ar5':'int32'}, engine='openpyxl')\n",
    "\n",
    "display(essd_gwp_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b346e53b-2c30-48d8-93f2-c826e65589d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ureg.define(\"CH4_Combustion = nan CH4\")\n",
    "ureg.define(\"CH4_Fugitive = nan CH4\")\n",
    "ureg.define(\"CH4_Process = nan CH4\")\n",
    "\n",
    "ch4_dict = {\n",
    "    'CH4 Biogenic': 'CH4',\n",
    "    'CH4 Fossil (Combustion)': 'CH4_Combustion',\n",
    "    'CH4 Fossil (Fugitive)': 'CH4_Fugitive',\n",
    "    'CH4 Fossil (Process)': 'CH4_Process'\n",
    "}\n",
    "\n",
    "def convert_gas_to_pint_species(s):\n",
    "    \"\"\"For a series S of gas species, return the species name known to pint\"\"\"\n",
    "    return [ch4_dict[g] if g in ch4_dict else g.replace('c-', 'C').replace('-','') for g in s.tolist()]\n",
    "\n",
    "essd_gwp_df = essd_gwp_df.assign(units=lambda x: convert_gas_to_pint_species(x.gas)).convert_dtypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61246f4-a441-4491-bb8d-920447730812",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "custom_meta_content = {\n",
    "    'title': 'Earth System Science Data (ESSD) Gas Species',\n",
    "    'author': essd_content_df[['Author & contact']].squeeze(),\n",
    "    'contact': essd_content_df[['Author & contact']].squeeze(),\n",
    "    'description': essd_content_df[['Regions']].squeeze(),\n",
    "    'release_date': essd_content_df[['Last date of compilation']].squeeze(),\n",
    "    # How should we describe our transformative step here?\n",
    "}\n",
    "\n",
    "custom_meta_fields = None\n",
    "\n",
    "ingest_table = 'gwp_100yr'\n",
    "columnschema = osc.create_table_schema_pairs(essd_gwp_df,\n",
    "                                             typemap={\"datetime64[ns]\":\"timestamp(6)\"})\n",
    "\n",
    "drop_table = engine.execute(f\"drop table if exists {ingest_schema}.{ingest_table}\")\n",
    "drop_table.fetchall()\n",
    "\n",
    "tabledef = f\"\"\"\n",
    "create table if not exists {ingest_catalog}.{ingest_schema}.{ingest_table}(\n",
    "{columnschema}\n",
    ") with (\n",
    "format = 'ORC'\n",
    ")\n",
    "\"\"\"\n",
    "print(tabledef)\n",
    "qres = engine.execute(tabledef)\n",
    "print(qres.fetchall())\n",
    "essd_gwp_df.to_sql(ingest_table,\n",
    "                   con=engine, schema=ingest_schema, if_exists='append',\n",
    "                   index=False,\n",
    "                   method=osc.TrinoBatchInsert(batch_size = 4000, verbose = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e75dc9d-8b88-4e16-a1c0-abf4faff3215",
   "metadata": {},
   "outputs": [],
   "source": [
    "essd_ch4_df = pd.read_excel(essd_tmpfile, sheet_name='CH4_gwps', dtype={'gwp_ar5':'int32', 'subsector':'str'}, engine='openpyxl').convert_dtypes()\n",
    "\n",
    "display(essd_ch4_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6045d1f3-e22c-4766-ac65-76f9f07ffd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_meta_content = {\n",
    "    'title': 'Earth System Science Data (ESSD) CH4 GWPs',\n",
    "    'author': essd_content_df[['Author & contact']].squeeze(),\n",
    "    'contact': essd_content_df[['Author & contact']].squeeze(),\n",
    "    'description': essd_content_df[['Regions']].squeeze(),\n",
    "    'release_date': essd_content_df[['Last date of compilation']].squeeze(),\n",
    "    # How should we describe our transformative step here?\n",
    "}\n",
    "\n",
    "custom_meta_fields = None\n",
    "\n",
    "ingest_table = 'ch4_gwp'\n",
    "columnschema = osc.create_table_schema_pairs(essd_ch4_df,\n",
    "                                             typemap={\"datetime64[ns]\":\"timestamp(6)\"})\n",
    "\n",
    "drop_table = engine.execute(f\"drop table if exists {ingest_schema}.{ingest_table}\")\n",
    "drop_table.fetchall()\n",
    "\n",
    "tabledef = f\"\"\"\n",
    "create table if not exists {ingest_catalog}.{ingest_schema}.{ingest_table}(\n",
    "{columnschema}\n",
    ") with (\n",
    "format = 'ORC'\n",
    ")\n",
    "\"\"\"\n",
    "print(tabledef)\n",
    "qres = engine.execute(tabledef)\n",
    "print(qres.fetchall())\n",
    "essd_ch4_df.to_sql(ingest_table,\n",
    "                   con=engine, schema=ingest_schema, if_exists='append',\n",
    "                   index=False,\n",
    "                   method=osc.TrinoBatchInsert(batch_size = 4000, verbose = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd652039-0578-48ca-8c41-70df83c0a012",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_gwp100_file = bObj = bucket.Object('ESSD/essd_ghg_data_gwp100.xlsx')\n",
    "essd_gwp100_tmpfile = f'/tmp/essd-gwp100.xlsx'\n",
    "s3_gwp100_file.download_file(essd_gwp100_tmpfile)\n",
    "timestamp = bObj.last_modified.isoformat()\n",
    "\n",
    "# This takes about 30sec to execute\n",
    "df = pd.read_excel(essd_gwp100_tmpfile, sheet_name='data',\n",
    "                   converters={'year': lambda x: pd.to_datetime(x, format='%Y')},\n",
    "                   dtype={'gwp100_ar5':'int32', 'value':'float64'},\n",
    "                   engine='openpyxl').convert_dtypes()\n",
    "\n",
    "# Put year at the end to make for more friendly partitioning\n",
    "year_index = df.columns.get_loc('year')\n",
    "essd_gwp100_df = df[df.columns[:year_index].to_list()\n",
    "                    + df.columns[year_index+1:].to_list()\n",
    "                    + [df.columns[year_index]]]\n",
    "\n",
    "display(essd_gwp100_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59161d29-6f20-4905-8db2-88fda45f59ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "essd_gwp100_content_df = pd.read_excel(essd_gwp100_tmpfile, sheet_name='info', header=None).dropna(axis=0).set_index(0).T\n",
    "custom_meta_content = {\n",
    "    'title': 'Earth System Science Data (ESSD) GWP100 Dataset',\n",
    "    'author': essd_content_df[['Author & contact']].squeeze(),\n",
    "    'contact': essd_content_df[['Author & contact']].squeeze(),\n",
    "    'description': essd_content_df[['Data description']].squeeze(),\n",
    "    'release_date': essd_content_df[['Last date of compilation']].squeeze(),\n",
    "    # How should we describe our transformative step here?\n",
    "}\n",
    "\n",
    "essd_gwp100_metadata_df = pd.read_excel(essd_gwp100_tmpfile, sheet_name='metadata')\n",
    "custom_meta_fields = { d['Variable']: {k:v for k,v in d.items() if k!='Variable' and v==v} for d in essd_metadata_df.to_dict('records') }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e543e243-a12f-4acd-a526-3b381424ac98",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_meta_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbee9347-b8ab-429d-b4f1-d3c64f037995",
   "metadata": {},
   "source": [
    "Construct the combined metadata by merging existing table metadata and custom metadata.\n",
    "Note: The metadata content must be JSON serialisable and encoded as bytes; the metadata key must also be encoded as bytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7d5791-7687-4414-903a-3569c5133a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "ingest_table = 'gwp100_data'\n",
    "columnschema = osc.create_table_schema_pairs(essd_gwp100_df,\n",
    "                                             typemap={\"datetime64[ns]\":\"timestamp(6)\"})\n",
    "\n",
    "drop_table = engine.execute(f\"drop table if exists {ingest_schema}.{ingest_table}\")\n",
    "drop_table.fetchall()\n",
    "\n",
    "tabledef = f\"\"\"\n",
    "create table if not exists {ingest_catalog}.{ingest_schema}.{ingest_table}(\n",
    "{columnschema}\n",
    ") with (\n",
    "format = 'ORC',\n",
    "partitioning = array['year']\n",
    ")\n",
    "\"\"\"\n",
    "print(tabledef)\n",
    "qres = engine.execute(tabledef)\n",
    "print(qres.fetchall())\n",
    "essd_gwp100_df.to_sql(ingest_table,\n",
    "                      con=engine, schema=ingest_schema, if_exists='append',\n",
    "                      index=False,\n",
    "                      method=osc.TrinoBatchInsert(batch_size = 4000, verbose = False))\n",
    "del(essd_gwp100_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8214a50-4cd3-47b7-9653-577b08fdebf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This table is not so large that we need to load it via the filesystem\n",
    "\n",
    "import io\n",
    "\n",
    "bObj = bucket.Object('ESSD/essd_lulucf_data.xlsx')\n",
    "lulucf_bytes = io.BytesIO(bucket.Object(bObj.key).get()['Body'].read())\n",
    "timestamp = bObj.last_modified.isoformat()\n",
    "\n",
    "df = pd.read_excel(lulucf_bytes, sheet_name='data', converters={'year': lambda x: pd.to_datetime(x, format='%Y')}, engine='openpyxl').convert_dtypes()\n",
    "\n",
    "# Put year at the end to make for more friendly partitioning\n",
    "year_index = df.columns.get_loc('year')\n",
    "lulucf_df = df[df.columns[:year_index].to_list()\n",
    "               + df.columns[year_index+1:].to_list()\n",
    "               + [df.columns[year_index]]]\n",
    "\n",
    "display(lulucf_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f2a649-36bd-4ac8-9c95-bdbf2666e794",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lulucf_content_df = pd.read_excel(lulucf_bytes, sheet_name='info', header=None).dropna(axis=0).set_index(0).T\n",
    "custom_meta_content = {\n",
    "    'title': 'Earth System Science Data (ESSD) Land Use Change and Forestry Dataset',\n",
    "    'author': lulucf_content_df[['Author']].squeeze(),\n",
    "    'contact': lulucf_content_df[['Contact']].squeeze(),\n",
    "    'description': lulucf_content_df[['Info']].squeeze(),\n",
    "    'release_date': essd_content_df[['Last date of compilation']].squeeze(),\n",
    "    # How should we describe our transformative step here?\n",
    "}\n",
    "\n",
    "custom_meta_fields = { 'Units': { k:'tCO2' for k in ['blue', 'houghton', 'oscar', 'mean'] }}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f368aae-7ce7-43d0-beea-95b32dc5b5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_meta_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34775abd-753d-457d-98e4-3bed4fdff440",
   "metadata": {},
   "source": [
    "Construct the combined metadata by merging existing table metadata and custom metadata.\n",
    "Note: The metadata content must be JSON serialisable and encoded as bytes; the metadata key must also be encoded as bytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14c87c2-2216-4e2d-b206-259185656d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "ingest_table = 'lulucf'\n",
    "columnschema = osc.create_table_schema_pairs(lulucf_df,\n",
    "                                             typemap={\"datetime64[ns]\":\"timestamp(6)\"})\n",
    "\n",
    "drop_table = engine.execute(f\"drop table if exists {ingest_schema}.{ingest_table}\")\n",
    "drop_table.fetchall()\n",
    "\n",
    "tabledef = f\"\"\"\n",
    "create table if not exists {ingest_catalog}.{ingest_schema}.{ingest_table}(\n",
    "{columnschema}\n",
    ") with (\n",
    "format = 'ORC',\n",
    "partitioning = array['year']\n",
    ")\n",
    "\"\"\"\n",
    "print(tabledef)\n",
    "qres = engine.execute(tabledef)\n",
    "print(qres.fetchall())\n",
    "lulucf_df.to_sql(ingest_table,\n",
    "                 con=engine, schema=ingest_schema, if_exists='append',\n",
    "                 index=False,\n",
    "                 method=osc.TrinoBatchInsert(batch_size = 4000, verbose = False))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a8aaa695-0f79-47dc-bbb1-995fa7d0cc45",
   "metadata": {},
   "source": [
    "# cur.execute('create schema if not exists osc_datacommons_dev.' + schemaname)\n",
    "\n",
    "cur.execute('show tables in essd')\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ec80d1-600a-4e0b-bb8b-2b2c8ca30f50",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load metadata following an ingestion process into trino metadata store\n",
    "\n",
    "### The schema is *metastore*, and the table names are *meta_schema*, *meta_table*, *meta_field*"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1072a510-07ef-4de4-be92-a5ca20922ddc",
   "metadata": {},
   "source": [
    "# Create metastore structure\n",
    "metastore = {'catalog':'osc_datacommons_dev',\n",
    "             'schema':'essd',\n",
    "             'table':tablename,\n",
    "             'metadata':custom_meta_content,\n",
    "             'uuid':ingest_uuid}\n",
    "# Create DataFrame\n",
    "df_meta = pd.DataFrame(metastore)\n",
    "# Print the output\n",
    "df_meta\n",
    "\n",
    "# ??? Now what?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcaf595-2877-46f1-86c4-37a83efd6e09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
